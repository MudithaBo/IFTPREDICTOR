% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predict.R
\name{predict_item_responses}
\alias{predict_item_responses}
\title{Predictions Using Item-Focused Tree Models}
\usage{
predict_item_responses(model, dataset, total_score)
}
\arguments{
\item{model}{A DIFtree model object.}

\item{dataset}{A data frame containing the required data. The 'total_score' column must be included.}

\item{total_score}{The name of the column in the dataset representing the total score (e.g., "total_score").}
}
\value{
A list containing:
\item{equations}{A set of logistic regression equations generated for each item.}
\item{predictions}{A dataset with predicted probabilities (\eqn{p}) and item responses (\eqn{I}), where \eqn{I = 1} if \eqn{p \geq 0.5}, and \eqn{I = 0} otherwise.}
}
\description{
This function predicts item response probabilities and item responses using the item-focused tree (IFT) model.
The IFT model combines logistic regression with recursive partitioning to detect Differential Item Functioning (DIF)
in dichotomous items. The model applies partitioning rules to the data, splitting it into homogeneous subgroups,
and uses logistic regression within each subgroup to explain the data. DIF detection is achieved by examining
potential group differences in item response patterns. This model produces tree diagrams to visualize homogeneous
subgroups within the population exhibiting similar response patterns and may therefore be helpful for developing personalized interventions and optimizing resource allocation in healthcare.
}
\details{
The logistic regression model for the \eqn{i}-th PROM item is defined as:

\deqn{
\log \left( \frac{P(Y_{pi} = 1 \mid S_{p}, g)}{P(Y_{pi} = 0 \mid S_{p}, g)} \right) = \eta_{pi} = \beta_{0i} + S_{p} \beta_{i} + \gamma_{ig},
}{
log(P(Y[pi] = 1 | S[p], g) / P(Y[pi] = 0 | S[p], g)) = eta[pi] = beta[0i] + S[p] beta[i] + gamma[ig],
}

where,
\eqn{Y_{pi} \in \{0, 1\}}: The response of person \eqn{p} to the \eqn{i}-th item.
\eqn{p = 1, 2, \dots, P}: The number of persons.
\eqn{i = 1, 2, \dots, I}: The number of items.
\eqn{g}: Group membership (\eqn{g = 0} for the reference group, \eqn{g = 1} for the focal group).
\eqn{S_p}: The ability level (e.g., total PROM score) of person \eqn{p}.
\eqn{\beta_{0i}}: The intercept or item difficulty parameter.
\eqn{\beta_{i}}: The slope or item discrimination parameter.
\eqn{\gamma_{ig}}: The group-specific parameter.

The IFT model extends this logistic regression model for DIF detection for the \eqn{i}-th PROM item:

\deqn{
\eta_{pi} = \beta_i S_p + \left[ \gamma_{ik} I(x_{pl} \leq c_l) + \gamma_{ir} I(x_{pl} > c_l) \right],
}{
eta[pi] = beta[i] S[p] + [gamma[ik] I(x[pl] <= c[l]) + gamma[ir] I(x[pl] > c[l])],
}

where,
\eqn{l = 1, \dots, L}: The number of partitions.
\eqn{c_l}: The threshold for the \eqn{l}-th variable.
\eqn{x_{pl} \leq c_l} and \eqn{x_{pl} > c_l}: The subgroups defined by tree partitions.
\eqn{I(\cdot)}: The indicator function (1 if true, 0 otherwise).
\eqn{\gamma_{ik}} and \eqn{\gamma_{ir}}: Subgroup-specific intercepts for logistic regression models in partitioned regions.
The terminal or leaf nodes of the tree represent the final groups of patients with similar response patterns.
The IFT model assumes unidimensionality, and the covariates \eqn{x_{pl}} can be either continuous or categorical.

If an item is never chosen for splitting, it is assumed to be free of DIF. The equation for an item free of DIF can be defined as:
\deqn{
\eta_{pi} = \beta_i S_p + \beta_0i,
}{
eta[pi] = beta[i] S[p] + beta[0i]
}
}
\examples{
if (requireNamespace("DIFtree", quietly = TRUE)) {
  # Load DIFtree
  library(DIFtree)

# Load the dataset
data("mydata", package = "IFTPredictor")

# Observe the data
head(mydata)

# Extract response and covariate data
Y <- mydata[, 1:20]  # Item responses
X <- mydata[, 21:24]  # Covariates

# Create total score column calcualting total item score for each patient
mydata$total_score <- rowSums(mydata[, 1:20])

# Fit the DIFtree model (Y = response data, X = covariate data)
mod <- DIFtree(Y, X, model = "Logistic", type = "udif", alpha = 0.05, nperm = 100, trace = TRUE)

# Predict item responses using the model and the total score
result <- predict_item_responses(mod, dataset = mydata, total_score = "total_score")

} else {
  message("The 'DIFtree' package is not installed. Please install it to run this example.")
}
}
\references{
Berger, Moritz and Tutz, Gerhard (2016): Detection of Uniform and Non-Uniform Differential Item Functioning by Item Focused Trees,
Journal of Educational and Behavioral Statistics 41(6), 559-592.
}
\seealso{
\code{\link[DIFtree]{DIFtree}} for training the DIFtree model.
}
\author{
Muditha Bodawatte Gedara (muditha.lakmali.1993@gmail.com),
Barret Monchka,
Lisa Lix
}
